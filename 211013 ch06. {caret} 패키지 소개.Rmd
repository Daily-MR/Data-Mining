---
title: "ch06. {caret} 패키지 소개"
author: "Jeong-Eun Lee"
date: '2021 10 13 '
output: html_document
---

+ {caret} 패키지 : classification and regression training
  + 복잡한 회귀와 분류 문제에 대한 모형 훈련과 조율 과정을 간소화하는 함수를 포함
  
### 6.2 사용절차 : PLS 회귀 예제
+ train() 함수
  1) 재표본을 사용하여 모형의 조율모수가 성능에 미치는 영향을 평가하고
  2) 이들 모수에서 최적의 모형을 선택하고
  3) 훈련 집합에서 모형 성능을 추정한다

+ createDataPartition() : 훈련용 데이터셋과 검증용 데이터셋으로 나눔
```{r}
library(caret)
library(mlbench)
data(Sonar)
set.seed(107)
inTrain = createDataPartition(y = Sonar$Class, p = 0.75, list = FALSE)
str(inTrain)
training = Sonar[inTrain, ]
testing = Sonar[-inTrain, ]
nrow(training)
nrow(testing)
```

+ train() 함수의 tuneLength = 옵션 : 평가되는 수를 제어
+ train() 함수의 tuneGrid = 옵션 : 특정값이 필요할 때 사용
+ trainControl() 함수의 summaryFunction = 옵션 : 관측값과 예측값을 취하여 성능 측도를 추정하는 함수에서 사용
+ trainControl() 함수의 classProbs = TRUE 옵션 : 통계적 계산을 포함하는 데 사용
  + 이게 없으면 ROC 계산이 이루어지지 않음

```{r}
set.seed(123)
library(pls)
ctrl = trainControl(method = "repeatedcv", repeats = 3,
                    classProbs = TRUE, summaryFunction = twoClassSummary)
plsFit = train(Class ~ ., data = training, method = "pls", tuneLength = 15,
               trControl = ctrl, metric = "ROC", preProc = c("center", "scale"))
plsFit
plot(plsFit)

plsClasses = predict(plsFit, newdata = testing)
str(plsClasses)
plsProbs = predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)

confusionMatrix(data = plsClasses, testing$Class)
```

+ Cohen의 카파통계량 : 범주형으로 이루어지는 평가에서 두 평가자 간의 일치도의 측도
  + 제안된 분류기의 성능이 각 범주의 빈도에 따라 임의로 예측하는 분류기의 성능보다 얼마나 우수한지를 알려줌
  + 우연에 의한 일치 가능성을 고려하므로 단순 퍼센트보다 로버스트한 측도
  + 정분류율의 평가로 쓰이기도 함
  
```{r}
rdaGrid = data.frame(gamma = (0:4) / 4, lambda = 3 / 4)
set.seed(123)
rdaFit = train(Class ~ ., data = training, method = "rda",
               tuneGrid = rdaGrid, trControl = ctrl, metric = "ROC")
rdaFit
rdaClasses = predict(rdaFit, newdata = testing)
confusionMatrix(rdaClasses, testing$Class)
resamps = resamples(list(pls = plsFit, rda = rdaFit))
summary(resamps)
xyplot(resamps, what = "BlandAltman")
diffs = diff(resamps)
summary(diffs)
```
+ BlandAltman : 서로 다른 두 분석 간의 합치도를 분석하는데 사용되는 데이터 plot 방법
+ bonferroni : 다중비교에서 생길 수 있는 오류 교정방법으로 관측데이터에 대해 $H_0$가 성립할 확률이 낮으면 $H_0$를 기각함으로써 $H_1$ 채택

### 6.4 {caret}을 이용한 변수선택
+ ROC 곡선 분석을 사용하여 추정 가능
+ 모형-기반 접근법의 장점 : 모형 성능과 보다 밀접하게 관계되며 예측변수들 간의 상관구조를 중요도 계산에 결합할 수 있음
+ varImp{caret} 함수 : train 객체 또는 특정 방법에 의한 결과 객체에 대한 변수 중요도를 계산

+ 예제 1.
```{r}
set.seed(100)
library(mlbench)
library(caret)
data(PimaIndiansDiabetes)

control = trainControl(method = "repeatedcV", number = 10, repeats = 3)
model = train(diabetes ~ ., data = PimaIndiansDiabetes, method = "lvq",
              preProcess = "scale", trControl = control)

importance = varImp(model, scale = FALSE)
print(importance)
plot(importance)
```

+ 재귀적 변수제거(=후진선택, RFE) : caret 패키지에서 제공되는 가장 널리 사용되는 자동 변수 선택 방법
+ rfe{caret} 함수 : RFE 알고리즘 수행
+ 예제 2.
```{r}
set.seed(50)
library(mlbench)
library(caret)
library(randomForest)
data(PimaIndiansDiabetes)

control = rfeControl(functions = rfFuncs, method = "cv", number = 10)
results = rfe(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
              sizes = c(1:8), rfeControl = control)
print(results)
predictors(results)
plot(results, type = c("g", "o"))
```

+ Regularization : 특정 제약항을 추가함으로써 일반화의 성질을 좋게 하는 목적으로 사용하며 정보는 주로 벌점의 형태로 주어짐

#### 6.5 예제 : {caret}을 이용한 기계학습
+ 절차 : 전처리 -> 데이터분할 -> 변수선택 -> 모형적합 -> 모수조율 -> 변수중요도추정 -> 예측 및 모형 평가

+ 예제 3. 
```{r}
setwd("C:/Users/X-Note/Desktop")
train = read.csv("loan.csv", encoding = "UTF-8")
str(train)
```

+ (a) 전처리 1 - 결측값 대치, 표준화
```{r}
sum(is.na(train))

library(mice)
library(caret)
md.pattern(train)

prePro = preProcess(train, method = c("knnImpute", "center", "scale"))
loanPre = predict(prePro, train)
sum(is.na(loanPre))
```
+ md.pattern{mice} : 결측값의 패턴 확인
  + knnImpute방법 : knn 방법으로 결측치 대치(결측치 제거x)
  
+ (b) 전처리 2 - 범주형 예측변수 처리
```{r}
# 종속변수를 숫자형 변수로 변환(0, 1로 recoding)
loanPre$Loan_Status = ifelse(loanPre$Loan_Status == "N", 0, 1)
id = loanPre$Loan_ID
loanPre$Loan_ID = NULL  # 1열(Loan_ID)은 제거하여 복잡성 줄임

# 범주형 변수에 대해 더미변수를 생성
dmy = dummyVars("~ .", data = loanPre, fullRank = T)
loanDummy = data.frame(predict(dmy, newdata = loanPre))
str(loanDummy)

# 반응변수를 원래의 범주형으로 돌려줌
loanDummy$Loan_Status = as.factor(loanDummy$Loan_Status)
```
+ dummyVars() : 범주형 예측변수에 대해 더미변수 생성
  + fullRank = TRUE 옵션 : (범주 수 - 1)개의 더미변수 생성
    + 역행렬이 계산되게 하려는 통계적 접근 방식
  + fullRank = FALSE 옵션 : (범주 수)개의 더미변수 생성
    + 요즘 많이 쓰는 방식
    
+ (c) 데이터 분할
```{r}
# 훈련용자료 75%, 검증용자료 25% 생성
set.seed(101)
index = createDataPartition(loanDummy$Loan_Status, p = 0.75, list = F)
loanTrain = loanDummy[index,]
loanTest = loanDummy[-index,]
```

+ set.seed() : 난수를 생성하는 프로그램에서 결과가 항상 다르게 나올 수 있는데 이 때 특정 결과의 재현성을 시행하기 위한 함수

+ (d) 변수 선택
```{r}
# rfe() 함수의 옵션 설정
set.seed(102)
control = rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 3, verbose = FALSE)
outcomeName = "Loan_Status"
predictors = names(loanTrain)[!names(loanTrain) %in% outcomeName]
predictorProfile = rfe(loanTrain[, predictors], loanTrain[, outcomeName],
                       rfeControl = control)
predictorProfile
names(predictorProfile)
predictors = predictorProfile$optVariables
```

+ (e) 모형 적합
```{r}
# {caret} 패키지에서 제공되는 알고리즘 확인
names(getModelInfo())

# 모형적합 예시
set.seed(103)
model_gbm = train(loanTrain[, predictors], loanTrain[, outcomeName], method = "gbm")
model_rf = train(loanTrain[, predictors], loanTrain[, outcomeName], method = "rf")
model_nnet = train(loanTrain[, predictors], loanTrain[, outcomeName], method = "nnet")
model_glm = train(loanTrain[, predictors], loanTrain[, outcomeName], method = "glm")

```

+ getModelInfo() : {caret} 패키지에서 제공되는 알고리즘 확인

+ (f) 모수 조율 : (e)에 비해 시간-소모적임에 유의
```{r}
# 모형의 성능 평가 방법을 지정 : 5-중첩 교차타당성 방법을 5회 반복
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)

# 1. tuneGrid() 함수를 이용한 모수 조율
modelLookup(model = "gbm")
grid = expand.grid(n.trees = c(10, 20, 50, 100, 500, 1000),
                   shrinkage = c(0.01, 0.05, 0.1, 0.5),
                   n.minobsinnode = c(3, 5, 10),
                   interaction.depth = c(1, 5, 10))

set.seed(104)
model_gbm_1 = train(loanTrain[, predictors], loanTrain[, outcomeName],
                    method = "gbm", trControl = fitControl, tuneGrid = grid)
plot(model_gbm_1)

# 2. tuneLength() 함수를 이용한 모수 조율
set.seed(105)
model_gbm_2 = train(loanTrain[, predictors], loanTrain[, outcomeName],
                    method = "gbm", trControl = fitControl, tuneLength = 10)
plot(model_gbm_2)
```

+ tuneGrid() : expand.grid()에서 지정한 모든 모수 조합에 대해 모형적합과 모형평가를 수행하여 최적의 모수 집합을 찾음
+ tuneLength() : 각 모수에 대해 값을 지정하는 대신 각 모수별로 고려해야 할 모수 값의 개수(길이)를 지정

+ (g) 변수 중요도 추정
```{r}
library(gbm)
varImp(object = model_gbm)
plot(varImp(object = model_gbm), main = "GBM - Variable Importance")

varImP(object = model_rf)
plot(varImp(object = model_rf), main = "RF - Variable Importance")

varImP(object = model_nnet)
plot(varImp(object = model_nnet), main = "NNET - Variable Importance")

varImP(object = model_glm)
plot(varImp(object = model_glm), main = "GLM - Variable Importance")
```

+ (h) 예측 및 모형 평가
```{r}
predictions = predict.train(object = model, gbm, loanTest[, predictors], type = "raw")
table(predictions)
confusionMatrix(predictions, loanTest[, outcomeName])
```

+ predict.train() : 검증용 자료에 대한 예측 수행
  + type = "raw" : 예측 클래스 제공
  + type = "prob" : 각 클래스에 속할 확률 제공
+ confusionMatrix() : 검증용 자료에 대한 모형평가 결과 제공

+ caret 패키지의 장점
  1) 단독으로 거의 모든 지도학습 문제를 다룸
  2) 전처리에서 예측모델링까지의 전 과정을 통일된 방식으로 수행
  3) 문법 체계가 매우 단순함
